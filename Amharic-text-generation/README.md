# Amharic-text-generation
This project implements an Amharic language model based on the GPT architecture using PyTorch. The model is trained on a dataset of Amharic text and can generate sequences of Amharic language text by predicting the next token in a sequence.

Features
Custom GPT architecture with self-attention and transformer layers
Trained on Amharic text data from am_data.txt
Token-level predictions for text generation
Supports training and evaluation on train/validation splits
Hyperparameters configurable via script
Weight initialization for better convergence based on recommendations
